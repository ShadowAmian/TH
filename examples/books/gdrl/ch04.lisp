(defpackage :gdrl-ch04
  (:use #:common-lisp
        #:mu
        #:th
        #:th.env)
  (:import-from #:th.env.bandits))

(in-package :gdrl-ch04)

(defun pure-exploitation (env &key (nepisodes 1000))
  (let ((q (zeros (env-action-space env)))
        (n (tensor.int (zeros (env-action-space env))))
        (qe (tensor nepisodes (env-action-space env)))
        (returns (tensor nepisodes))
        (actions (tensor.int nepisodes))
        (name "Pure exploitation"))
    (loop :for e :from 0 :below nepisodes
          :for maxres = ($max q 0)
          :for action = ($ (cadr maxres) 0)
          :for tx = (env-step! env action)
          :for reward = ($2 tx)
          :do (progn
                (incf ($ n action))
                (incf ($ q action) (/ (- reward ($ q action)) ($ n action)))
                (setf ($ qe e) q)
                (setf ($ returns e) reward)
                (setf ($ actions e) action)))
    (list name returns qe actions)))

(defun pure-exploration (env &key (nepisodes 1000))
  (let ((q (zeros (env-action-space env)))
        (n (tensor.int (zeros (env-action-space env))))
        (qe (tensor nepisodes (env-action-space env)))
        (returns (tensor nepisodes))
        (actions (tensor.int nepisodes))
        (name "Pure exploration"))
    (loop :for e :from 0 :below nepisodes
          :for action = (random ($count q))
          :for tx = (env-step! env action)
          :for reward = ($2 tx)
          :do (progn
                (incf ($ n action))
                (incf ($ q action) (/ (- reward ($ q action)) ($ n action)))
                (setf ($ qe e) q)
                (setf ($ returns e) reward)
                (setf ($ actions e) action)))
    (list name returns qe actions)))

(defun epsilon-greedy (env &key (epsilon 0.01) (nepisodes 1000))
  (let ((q (zeros (env-action-space env)))
        (n (tensor.int (zeros (env-action-space env))))
        (qe (tensor nepisodes (env-action-space env)))
        (returns (tensor nepisodes))
        (actions (tensor.int nepisodes))
        (name (format nil "E-greedy ~A" epsilon)))
    (loop :for e :from 0 :below nepisodes
          :for maxres = ($max q 0)
          :for action = (if (> (random 1D0) epsilon)
                            ($ (cadr maxres) 0)
                            (random ($count q)))
          :for tx = (env-step! env action)
          :for reward = ($2 tx)
          :do (progn
                (incf ($ n action))
                (incf ($ q action) (/ (- reward ($ q action)) ($ n action)))
                (setf ($ qe e) q)
                (setf ($ returns e) reward)
                (setf ($ actions e) action)))
    (list name returns qe actions)))

(defun linear-decreasing-epsilon-greedy (env &key (epsilon0 1D0)
                                               (min-epsilon 0.01)
                                               (decay-ratio 0.05)
                                               (nepisodes 1000))
  (let ((q (zeros (env-action-space env)))
        (n (tensor.int (zeros (env-action-space env))))
        (qe (tensor nepisodes (env-action-space env)))
        (returns (tensor nepisodes))
        (actions (tensor.int nepisodes))
        (name (format nil "Linear e-greedy ~A ~A ~A" epsilon0 min-epsilon decay-ratio)))
    (loop :for e :from 0 :below nepisodes
          :for decay-episodes = (* nepisodes decay-ratio)
          :for epsilon = (let ((epsilon (- 1D0 (/ e decay-episodes))))
                           (setf epsilon (* epsilon (- epsilon0 min-epsilon)))
                           (incf epsilon min-epsilon)
                           (if (< epsilon min-epsilon)
                               (setf epsilon min-epsilon))
                           (if (> epsilon epsilon0)
                               (setf epsilon epsilon0))
                           epsilon)
          :for maxres = ($max q 0)
          :for action = (if (> (random 1D0) epsilon)
                            ($ (cadr maxres) 0)
                            (random ($count q)))
          :for tx = (env-step! env action)
          :for reward = ($2 tx)
          :do (progn
                (incf ($ n action))
                (incf ($ q action) (/ (- reward ($ q action)) ($ n action)))
                (setf ($ qe e) q)
                (setf ($ returns e) reward)
                (setf ($ actions e) action)))
    (list name returns qe actions)))

(let* ((nepisodes 1000)
       (epsilon0 1D0)
       (min-epsilon 0.01)
       (decay-ratio 0.1)
       (decay-episodes (round (* nepisodes decay-ratio)))
       (rem-episodes (- nepisodes decay-episodes))
       (epsilons (let ((es ($/ 0.01 (logspace -2 0 decay-episodes))))
                   (setf es ($* es ($- epsilon0 min-epsilon)))
                   (setf es ($+ es min-epsilon))
                   es)))
  ($last epsilons))

(defun exponential-decreasing-epsilon-greedy (env &key (epsilon0 1D0)
                                                    (min-epsilon 0.01)
                                                    (decay-ratio 0.1)
                                                    (nepisodes 1000))
  (let* ((q (zeros (env-action-space env)))
         (n (tensor.int (zeros (env-action-space env))))
         (qe (tensor nepisodes (env-action-space env)))
         (returns (tensor nepisodes))
         (actions (tensor.int nepisodes))
         (decay-episodes (round (* nepisodes decay-ratio)))
         (epsilons (let ((es ($/ 0.01 (logspace -2 0 decay-episodes))))
                     (setf es ($* es (- epsilon0 min-epsilon)))
                     (incf es min-epsilon)
                     (let ((eps (tensor nepisodes)))
                       ($fill! eps ($last es))
                       (setf ($subview eps 0 ($count es)) es)
                       eps)))
         (name (format nil "Exponential e-greedy ~A ~A ~A" epsilon0 min-epsilon decay-ratio)))
    (loop :for e :from 0 :below nepisodes
          :for decay-episodes = (* nepisodes decay-ratio)
          :for epsilon = ($ epsilons e)
          :for maxres = ($max q 0)
          :for action = (if (> (random 1D0) epsilon)
                            ($ (cadr maxres) 0)
                            (random ($count q)))
          :for tx = (env-step! env action)
          :for reward = ($2 tx)
          :do (progn
                (incf ($ n action))
                (incf ($ q action) (/ (- reward ($ q action)) ($ n action)))
                (setf ($ qe e) q)
                (setf ($ returns e) reward)
                (setf ($ actions e) action)))
    (list name returns qe actions)))

(defun optimistic-initialization (env &key (optimistic-estimate 1D0)
                                        (initial-count 100)
                                        (nepisodes 1000))
  (let ((q (-> (tensor (env-action-space env)) ($fill! optimistic-estimate)))
        (n (-> (tensor.int (env-action-space env)) ($fill! initial-count)))
        (qe (tensor nepisodes (env-action-space env)))
        (returns (tensor nepisodes))
        (actions (tensor.int nepisodes))
        (name (format nil "Optimistic ~A ~A" optimistic-estimate initial-count)))
    (loop :for e :from 0 :below nepisodes
          :for maxres = ($max q 0)
          :for action = ($ (cadr maxres) 0)
          :for tx = (env-step! env action)
          :for reward = ($2 tx)
          :do (progn
                (incf ($ n action))
                (incf ($ q action) (/ (- reward ($ q action)) ($ n action)))
                (setf ($ qe e) q)
                (setf ($ returns e) reward)
                (setf ($ actions e) action)))
    (list name returns qe actions)))
